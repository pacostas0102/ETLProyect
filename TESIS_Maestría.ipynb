{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f73efd-e5f2-4a64-b71c-19da1f5994e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 --version\n",
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext.getOrCreate()\n",
    "#print(sc.pythonVer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e70817c6-418c-4ccf-b321-7b03e485f107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "NumPy version: 2.2.1\n",
      "Xlrd version: 2.0.1\n",
      "Openpyxl version: 3.1.5\n",
      "PySpark version: 3.5.4\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"PYSPARK_PYTHON\"] = \"python3\"  # O \"python\" si ese es tu ejecutable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import openpyxl\n",
    "import pyspark\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Xlrd version:\", xlrd.__version__)\n",
    "print(\"Openpyxl version:\", openpyxl.__version__)\n",
    "print(\"PySpark version:\", pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c94b79be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- -----------\n",
      "asttokens           3.0.0\n",
      "colorama            0.4.6\n",
      "comm                0.2.2\n",
      "contourpy           1.3.1\n",
      "cycler              0.12.1\n",
      "debugpy             1.8.11\n",
      "decorator           5.1.1\n",
      "et_xmlfile          2.0.0\n",
      "executing           2.1.0\n",
      "fonttools           4.55.3\n",
      "importlib_resources 6.5.2\n",
      "ipykernel           6.29.5\n",
      "ipython             8.31.0\n",
      "jedi                0.19.2\n",
      "Jinja2              3.1.5\n",
      "jupyter_client      8.6.3\n",
      "jupyter_core        5.7.2\n",
      "kiwisolver          1.4.8\n",
      "MarkupSafe          3.0.2\n",
      "matplotlib          3.10.0\n",
      "matplotlib-inline   0.1.7\n",
      "nest-asyncio        1.6.0\n",
      "numpy               2.2.1\n",
      "openpyxl            3.1.5\n",
      "packaging           24.2\n",
      "pandas              2.2.3\n",
      "parso               0.8.4\n",
      "pillow              11.1.0\n",
      "platformdirs        4.3.6\n",
      "prompt_toolkit      3.0.48\n",
      "psutil              6.1.1\n",
      "pure_eval           0.2.3\n",
      "py4j                0.10.9.7\n",
      "Pygments            2.18.0\n",
      "pyparsing           3.2.1\n",
      "pyspark             3.5.4\n",
      "python-dateutil     2.9.0.post0\n",
      "pytz                2024.2\n",
      "pywin32             308\n",
      "pyzmq               26.2.0\n",
      "scipy               1.15.1\n",
      "seaborn             0.13.2\n",
      "six                 1.17.0\n",
      "stack-data          0.6.3\n",
      "sweetviz            2.3.1\n",
      "tornado             6.4.2\n",
      "tqdm                4.67.1\n",
      "traitlets           5.14.3\n",
      "typing_extensions   4.12.2\n",
      "tzdata              2024.2\n",
      "wcwidth             0.2.13\n",
      "xlrd                2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\paula\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e844ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\paula\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c672a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y pyspark\n",
    "#pip uninstall -yspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0468ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip cache purge\n",
    "\n",
    "#!pip install pyspark==3.5.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2006e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: sweetviz in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sweetviz) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sweetviz) (1.15.1)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sweetviz) (3.1.5)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sweetviz) (6.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2>=2.11.1->sweetviz) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.43.0->sweetviz) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\paula\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Libreria para análisis EDA\n",
    "!pip install matplotlib seaborn sweetviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999ec378-e20f-4900-ae0f-e00473f559d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\paula\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edda788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.5)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\paula\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\paula\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0691c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3b570e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosEntrada\\LOCardReports\\Cash_Advance_Transaction-20240903-0921.xls'\n",
    "\n",
    "# Especificar la ruta del archivo Excel\n",
    "output_path = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado2.xlsx'\n",
    "\n",
    "# Especificar la ruta del archivo Excel\n",
    "output_path3 = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado3.xlsx'\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos de Entrada\n",
    "folder_path = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosEntrada\\LOCardReports'\n",
    "host_folder_path = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosEntrada\\HostReports'\n",
    "Logs_path = r'C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosEntrada\\Logs\\ATM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315b16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformacion Nulos\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65 entries, 0 to 64\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   nanCS25         65 non-null     object\n",
      " 1   nanSEQUENCE     65 non-null     object\n",
      " 2   nanCARD         65 non-null     object\n",
      " 3   nanHOST         65 non-null     object\n",
      " 4   nanTRANSACTION  65 non-null     object\n",
      " 5   nanTRANS        65 non-null     object\n",
      " 6   nanFEE          65 non-null     object\n",
      " 7   nannan          65 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 4.2+ KB\n",
      "            nanCS25 nanSEQUENCE nanCARD  nanHOST nanTRANSACTION  nanTRANS  \\\n",
      "count            65          65      65       65             65        65   \n",
      "unique           65          65      33       18              4        16   \n",
      "top     DATE & TIME      NUMBER    9744        0        Credit        100   \n",
      "freq              1           1       5       48             57        12   \n",
      "\n",
      "        nanFEE  nannan  \n",
      "count       65      65  \n",
      "unique      10       4  \n",
      "top          0  Denied  \n",
      "freq        48      47  \n",
      "nanCS25           0\n",
      "nanSEQUENCE       0\n",
      "nanCARD           0\n",
      "nanHOST           0\n",
      "nanTRANSACTION    0\n",
      "nanTRANS          0\n",
      "nanFEE            0\n",
      "nannan            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "hist method requires numerical or datetime columns, nothing to plot.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Histograma para todas las columnas numéricas\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Boxplot para una columna específica (ejemplo: columna \"TRANSACTIONTYPE\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\plotting\\_core.py:251\u001b[0m, in \u001b[0;36mhist_frame\u001b[1;34m(data, column, by, grid, xlabelsize, xrot, ylabelsize, yrot, ax, sharex, sharey, figsize, layout, bins, backend, legend, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03mMake a histogram of the DataFrame's columns.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    >>> hist = df.hist(bins=3)\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m plot_backend \u001b[38;5;241m=\u001b[39m _get_plot_backend(backend)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabelsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxlabelsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxrot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxrot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabelsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mylabelsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43myrot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myrot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\plotting\\_matplotlib\\hist.py:549\u001b[0m, in \u001b[0;36mhist_frame\u001b[1;34m(data, column, by, grid, xlabelsize, xrot, ylabelsize, yrot, ax, sharex, sharey, figsize, layout, bins, legend, **kwds)\u001b[0m\n\u001b[0;32m    546\u001b[0m naxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m naxes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist method requires numerical or datetime columns, nothing to plot.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    553\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m create_subplots(\n\u001b[0;32m    554\u001b[0m     naxes\u001b[38;5;241m=\u001b[39mnaxes,\n\u001b[0;32m    555\u001b[0m     ax\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    560\u001b[0m     layout\u001b[38;5;241m=\u001b[39mlayout,\n\u001b[0;32m    561\u001b[0m )\n\u001b[0;32m    562\u001b[0m _axes \u001b[38;5;241m=\u001b[39m flatten_axes(axes)\n",
      "\u001b[1;31mValueError\u001b[0m: hist method requires numerical or datetime columns, nothing to plot."
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------Análisis EDA----------------------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar archivo Excel\n",
    "df= pd.read_excel(file_path, sheet_name=\"Sheet2\", skiprows=2, header=None) # Cambia por la ruta de tu archivo\n",
    "new_columns = df.iloc[2].astype(str) + df.iloc[3].astype(str)\n",
    "df.columns = new_columns  # Asignar los nuevos encabezados\n",
    "df = df[4:]  # Eliminar las filas de encabezado original (0, 1 y 2)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "#df['file_name'] = os.path.basename(file)# Agregar el nombre del archivo    \n",
    "#print(\"Nombre del archivo:\", file_name)\n",
    "    #Tranformación 1 - Nulos\n",
    "    # Eliminar columnas donde todos los valores son NaN\n",
    "print (\"Transformacion Nulos\\n\")\n",
    "df = df.dropna(axis=1, how='all')\n",
    "    #Tranformación 3 - Reemplaza NaN con un valor predeterminado si es necesario\n",
    "df = df.fillna(0)\n",
    "#df = df.loc[df[\"CS25DATE & TIME\"] != \"Totals:\"]\n",
    "# Obtener información básica sobre el DataFrame\n",
    "df.info()\n",
    "\n",
    "# Resumen estadístico de las columnas numéricas\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# Histograma para todas las columnas numéricas\n",
    "df.hist(bins=20, figsize=(10, 8))\n",
    "plt.show()\n",
    "\n",
    "# Boxplot para una columna específica (ejemplo: columna \"TRANSACTIONTYPE\")\n",
    "sns.boxplot(x=df[\"nanCARD\"])\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de correlación\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras para una columna categórica (ejemplo: \"categoría\")\n",
    "sns.countplot(x=\"nanTRANS\", data=df)\n",
    "plt.show()\n",
    "# Generar el reporte\n",
    "#reporte = sv.analyze(data)\n",
    "\n",
    "# Guardar el reporte\n",
    "#reporte.show_html(\"reporte_sweetviz.html\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b40b477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del archivo: ATM_Transaction_Summary-20240903-0919.xls\n",
      "Transformacion Nulos\n",
      "\n",
      "El archivo contiene 'ATM' en el nombre.\n",
      "              DATE & TIME    SEQUENCENUMBER CARDNUMBER HOSTSEQ NUMBER  \\\n",
      "0     08/23/2024 08:13:19  2024082308124108       7816           1452   \n",
      "1     08/23/2024 08:27:15  2024082308262908       9584           1453   \n",
      "2     08/23/2024 08:46:09  2024082308453408       4299           1454   \n",
      "3     08/23/2024 09:06:48  2024082309063308       2610              0   \n",
      "4     08/23/2024 09:08:19  2024082309074608       6718           1456   \n",
      "...                   ...               ...        ...            ...   \n",
      "1194  08/31/2024 03:33:35  2024083103330508       6909           2872   \n",
      "1195  08/31/2024 04:15:39  2024083104150508       7577           2874   \n",
      "1196  08/31/2024 04:45:25  2024083104445708       6160              0   \n",
      "1197  08/31/2024 04:48:35  2024083104480808       1284           2877   \n",
      "1198  08/31/2024 05:10:02  2024083105092708       5484           2878   \n",
      "\n",
      "     TRANSACTIONTYPE  TRANSAMOUNT($) COINSTOTAL($)  DISPENSEDTOTAL($)  FEE($)  \\\n",
      "0         Withdrawal           100.0             0              100.0       0   \n",
      "1         Withdrawal            60.0             0               60.0       0   \n",
      "2         Withdrawal           600.0             0              600.0       0   \n",
      "3         Withdrawal          1000.0             0                0.0       0   \n",
      "4         Withdrawal          1000.0             0             1000.0       0   \n",
      "...              ...             ...           ...                ...     ...   \n",
      "1194      Withdrawal           100.0             0              100.0       0   \n",
      "1195      Withdrawal            60.0             0               60.0       0   \n",
      "1196      Withdrawal           100.0             0                0.0       0   \n",
      "1197      Withdrawal            40.0             0               40.0       0   \n",
      "1198      Withdrawal           200.0             0              200.0       0   \n",
      "\n",
      "         STATUS                                  file_name  \n",
      "0     Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1     Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "2     Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "3        Denied  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "4     Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "...         ...                                        ...  \n",
      "1194  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1195  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1196     Denied  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1197  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1198  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "\n",
      "[1199 rows x 11 columns]\n",
      "Nombre del archivo: Cash_Advance_Transaction-20240903-0921.xls\n",
      "Transformacion Nulos\n",
      "\n",
      "El archivo contiene 'Cash_Advance' en el nombre.\n",
      "Nombre del archivo: Debit_Dispense-20240903-0923.xls\n",
      "Transformacion Nulos\n",
      "\n",
      "El archivo contiene 'Debit_Dispense' en el nombre.\n",
      "Nombre del archivo: Pos_Ticket_Purchase-20240903-0925.xls\n",
      "Transformacion Nulos\n",
      "\n",
      "El archivo contiene 'Pos_Ticket_Purchase' en el nombre.\n",
      "DataFrame combinado con nombres de archivo:\n",
      "              DATE & TIME    SEQUENCENUMBER CARDNUMBER HOSTSEQ NUMBER  \\\n",
      "0     08/23/2024 08:13:19  2024082308124108       7816           1452   \n",
      "1     08/23/2024 08:27:15  2024082308262908       9584           1453   \n",
      "2     08/23/2024 08:46:09  2024082308453408       4299           1454   \n",
      "3     08/23/2024 09:06:48  2024082309063308       2610              0   \n",
      "4     08/23/2024 09:08:19  2024082309074608       6718           1456   \n",
      "...                   ...               ...        ...            ...   \n",
      "1354  08/30/2024 09:34:30  0830202409341815       2868           2684   \n",
      "1355  08/30/2024 16:06:52  0830202416064291       1109           2745   \n",
      "1356  08/30/2024 22:41:05  0830202422404635       8418           2820   \n",
      "1357  08/30/2024 22:42:38  0830202422422944       8418           2821   \n",
      "1358  08/30/2024 22:44:00  0830202422434897       8418              0   \n",
      "\n",
      "            TRANSACTIONTYPE  TRANSAMOUNT($) COINSTOTAL($)  DISPENSEDTOTAL($)  \\\n",
      "0                Withdrawal           100.0             0              100.0   \n",
      "1                Withdrawal            60.0             0               60.0   \n",
      "2                Withdrawal           600.0             0              600.0   \n",
      "3                Withdrawal          1000.0             0                0.0   \n",
      "4                Withdrawal          1000.0             0             1000.0   \n",
      "...                     ...             ...           ...                ...   \n",
      "1354  Debit Ticket Purchase          2500.0             0                0.0   \n",
      "1355  Debit Ticket Purchase          1000.0             0                0.0   \n",
      "1356  Debit Ticket Purchase          1000.0             0                0.0   \n",
      "1357  Debit Ticket Purchase          1000.0             0                0.0   \n",
      "1358  Debit Ticket Purchase           500.0             0                0.0   \n",
      "\n",
      "      FEE($)     STATUS                                  file_name  \n",
      "0        0.0  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "1        0.0  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "2        0.0  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "3        0.0     Denied  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "4        0.0  Completed  ATM_Transaction_Summary-20240903-0919.xls  \n",
      "...      ...        ...                                        ...  \n",
      "1354   125.0  Completed      Pos_Ticket_Purchase-20240903-0925.xls  \n",
      "1355    50.0  Completed      Pos_Ticket_Purchase-20240903-0925.xls  \n",
      "1356    50.0  Completed      Pos_Ticket_Purchase-20240903-0925.xls  \n",
      "1357    50.0  Completed      Pos_Ticket_Purchase-20240903-0925.xls  \n",
      "1358     0.0     Denied      Pos_Ticket_Purchase-20240903-0925.xls  \n",
      "\n",
      "[1359 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\4163257213.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\4163257213.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\4163257213.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\4163257213.py:21: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo exportado exitosamente a C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado2.xlsx\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------LiveOffice Card Reports----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Obtener una lista de todos los archivos Excel en la carpeta\n",
    "file_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.xls', '.xlsx'))]\n",
    "\n",
    "dataframes = []\n",
    "for file in file_list:\n",
    "    df = pd.read_excel(file, sheet_name=\"Sheet2\", skiprows=3, header=None)\n",
    "    file_name = os.path.basename(file)\n",
    "    new_columns = df.iloc[2].astype(str) + df.iloc[3].astype(str)\n",
    "    df.columns = new_columns  # Asignar los nuevos encabezados\n",
    "    df = df[4:]  # Eliminar las filas de encabezado original (0, 1 y 2)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['file_name'] = os.path.basename(file)# Agregar el nombre del archivo    \n",
    "    print(\"Nombre del archivo:\", file_name)\n",
    "    #Tranformación 1 - Nulos\n",
    "    # Eliminar columnas donde todos los valores son NaN\n",
    "    print (\"Transformacion Nulos\\n\")\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    #Tranformación 3 - Reemplaza NaN con un valor predeterminado si es necesario\n",
    "    df = df.fillna(0)    \n",
    "    # Encuentra el nombre exacto de la columna que contiene 'DATE & TIME'\n",
    "    target_column = df.filter(like=\"DATE & TIME\").columns[0]\n",
    "    # Renombra dinámicamente la columna encontrada\n",
    "    df = df.rename(columns={target_column: \"DATE & TIME\"})\n",
    "    df = df.loc[df[\"DATE & TIME\"] != \"Totals:\"]\n",
    "    #print(df) \n",
    "    if \"ATM\" in file_name:\n",
    "        print(\"El archivo contiene 'ATM' en el nombre.\")\n",
    "        df.insert(loc=df.columns.get_loc(\"nanSTATUS\"), column=\"FEE($)\", value=0)\n",
    "        #Tranformación 2 - Limpia y Convertir las columnas numéricas a float\n",
    "        df['DISPENSEDTOTAL($)'] = pd.to_numeric(df['DISPENSEDTOTAL($)'], errors='coerce').fillna(0).astype(float)\n",
    "        df['TRANSAMOUNT($)'] = pd.to_numeric(df['TRANSAMOUNT($)'], errors='coerce').astype(float)\n",
    "        df = df.drop(['DISPENSED QTYS$1', 'nan$5', 'nan$10', 'nan$20', 'nan$50', 'nan$100'], axis=1)\n",
    "        #Tranformación 4-  Convierte las columnas categóricas o de texto a tipo `str`\n",
    "        df['TRANSTYPE'] = df['TRANSTYPE'].astype(str)        \n",
    "        df['SEQUENCENUMBER'] = df['SEQUENCENUMBER'].astype(str)        \n",
    "        df['nanCARD#'] = df['nanCARD#'].astype(str)        \n",
    "        df['HOSTSEQ NUMBER'] = df['HOSTSEQ NUMBER'].astype(str)\n",
    "        # limpiar la columna TRANSACTIONTYPE\n",
    "        df[\"TRANSTYPE\"] = df[\"TRANSTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSTYPE\"] = df[\"TRANSTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        df = df.rename(columns={\"nanSTATUS\": \"STATUS\", \"nanCARD#\": \"CARDNUMBER\", \"TRANSTYPE\": \"TRANSACTIONTYPE\"})\n",
    "        print(df) \n",
    "    elif \"Cash_Advance\" in file_name:\n",
    "        print(\"El archivo contiene 'Cash_Advance' en el nombre.\")  # Agregar el nombre del archivo\n",
    "        #Tranformación 2 - Limpia y Convertir las columnas numéricas a float\n",
    "        status_column_index = df.columns.get_loc(\"FEE($)\")\n",
    "        df['TRANSAMOUNT($)'] = pd.to_numeric(df['TRANSAMOUNT($)'], errors='coerce').astype(float)\n",
    "        df.insert(loc=status_column_index, column=\"DISPENSEDTOTAL($)\", value=0)\n",
    "        df.insert(loc=status_column_index, column=\"COINSTOTAL($)\", value=0)        \n",
    "        #Tranformación 4-  Convierte las columnas categóricas o de texto a tipo `str`\n",
    "        df['TRANSACTIONTYPE'] = df['TRANSACTIONTYPE'].astype(str)\n",
    "        df['SEQUENCENUMBER'] = df['SEQUENCENUMBER'].astype(str)        \n",
    "        df['CARDNUMBER'] = df['CARDNUMBER'].astype(str)        \n",
    "        df['HOSTSEQ NUMBER'] = df['HOSTSEQ NUMBER'].astype(str)\n",
    "        # limpiar la columna TRANSACTIONTYPE\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        # Filtrar los registros que no sean 'Credit'\n",
    "        df = df.loc[df[\"TRANSACTIONTYPE\"] != \"Credit\"]\n",
    "        df = df.rename(columns={\"nanSTATUS\": \"STATUS\"})\n",
    "    elif \"Debit_Dispense\" in file_name:\n",
    "        print(\"El archivo contiene 'Debit_Dispense' en el nombre.\")  # Agregar el nombre del archivo  \n",
    "          #Tranformación 2 - Limpia y Convertir las columnas numéricas a float\n",
    "        status_column_index = df.columns.get_loc(\"FEE($)\")       \n",
    "        df.insert(loc=status_column_index, column=\"DISPENSEDTOTAL($)\", value=0)\n",
    "        df.insert(loc=status_column_index, column=\"COINSTOTAL($)\", value=0)        \n",
    "        #Tranformación 4-  Convierte las columnas categóricas o de texto a tipo `str`\n",
    "        df['TRANSACTIONTYPE'] = df['TRANSACTIONTYPE'].astype(str)\n",
    "        df['SEQUENCENUMBER'] = df['SEQUENCENUMBER'].astype(str)        \n",
    "        df['CARDNUMBER'] = df['CARDNUMBER'].astype(str)        \n",
    "        df['HOSTSEQ NUMBER'] = df['HOSTSEQ NUMBER'].astype(str)\n",
    "        # limpiar la columna TRANSACTIONTYPE\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        df = df.rename(columns={\"nanSTATUS\": \"STATUS\"})\n",
    "    elif \"Pos_Ticket_Purchase\" in file_name:\n",
    "        print(\"El archivo contiene 'Pos_Ticket_Purchase' en el nombre.\")  # Agregar el nombre del archivo  \n",
    "          #Tranformación 2 - Limpia y Convertir las columnas numéricas a float\n",
    "        status_column_index = df.columns.get_loc(\"FEE($)\")       \n",
    "        df.insert(loc=status_column_index, column=\"DISPENSEDTOTAL($)\", value=0)\n",
    "        df.insert(loc=status_column_index, column=\"COINSTOTAL($)\", value=0)        \n",
    "        #Tranformación 4-  Convierte las columnas categóricas o de texto a tipo `str`\n",
    "        df['TRANSACTIONTYPE'] = df['TRANSACTIONTYPE'].astype(str)\n",
    "        df['SEQUENCENUMBER'] = df['SEQUENCENUMBER'].astype(str)        \n",
    "        df['CARDNUMBER'] = df['CARDNUMBER'].astype(str)        \n",
    "        df['HOSTSEQ NUMBER'] = df['HOSTSEQ NUMBER'].astype(str)\n",
    "        # limpiar la columna TRANSACTIONTYPE\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.strip()  # Elimina espacios antes y después\n",
    "        df[\"TRANSACTIONTYPE\"] = df[\"TRANSACTIONTYPE\"].str.replace(r\"\\s+\", \" \", regex=True)  # Reemplaza múltiples espacios con uno solo\n",
    "        df = df.rename(columns={\"nanSTATUS\": \"STATUS\"})\n",
    "    else:\n",
    "        print(\"otra Opcion\") \n",
    "    dataframes.append(df)\n",
    "\n",
    "df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "print(\"DataFrame combinado con nombres de archivo:\")\n",
    "print(df_combined)\n",
    "\n",
    "\n",
    "#Código para concatenar filas 3 y 4 para los titulos \n",
    "\n",
    "#Lectura del archivo\n",
    "#df = pd.read_excel(file_path, sheet_name=\"Sheet2\", skiprows=3, header=None)\n",
    "#file_name = os.path.basename(file_path)\n",
    "#print(\"Nombre del archivo:\", file_name)\n",
    "\n",
    "#Antes de unificar\n",
    "#print (\"Titulos de archivo fuente:\")\n",
    "#print(df)\n",
    "\n",
    "#Combinar filas 3 y 4 \n",
    "\n",
    "#new_columns = df.iloc[2].astype(str) + df.iloc[3].astype(str)\n",
    "#df.columns = new_columns  # Asignar los nuevos encabezados\n",
    "#df = df[4:]  # Eliminar las filas de encabezado original (0, 1 y 2)\n",
    "# Reiniciar el índice\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#print(\"Después de la unificación:\")\n",
    "#print(df)\n",
    "\n",
    "#print(df.dtypes)\n",
    "\n",
    "# Agregar la columna del nombre del archivo\n",
    "#df[\"file_name\"] = file_name\n",
    "\n",
    "#Tranformación 1 - Nulos\n",
    "# Eliminar columnas donde todos los valores son NaN\n",
    "#print (\"Transformacion Nulos\\n\")\n",
    "#df = df.dropna(axis=1, how='all')\n",
    "#print(df) \n",
    "\n",
    "#Tranformación 2 - Limpia y Convertir las columnas numéricas a float\n",
    "#df['DISPENSEDTOTAL($)'] = pd.to_numeric(df['DISPENSEDTOTAL($)'], errors='coerce').fillna(0).astype(float)\n",
    "#df['TRANSAMOUNT($)'] = pd.to_numeric(df['TRANSAMOUNT($)'], errors='coerce').astype(float)\n",
    "\n",
    "#Tranformación 3 - Reemplaza NaN con un valor predeterminado si es necesario\n",
    "#df = df.fillna(0)\n",
    "\n",
    "#Tranformación 4-  Convierte las columnas categóricas o de texto a tipo `str`\n",
    "#df['TRANSTYPE'] = df['TRANSTYPE'].astype(str)\n",
    "\n",
    "#print(df)\n",
    "\n",
    "\n",
    "#df = df.drop(['DISPENSED QTYS$1', 'nan$5', 'nan$10', 'nan$20', 'nan$50', 'nan$100'], axis=1)\n",
    "\n",
    "# Guardar el DataFrame de Pandas en Excel\n",
    "df_combined.to_excel(output_path, index=False, engine='openpyxl') \n",
    "print(f\"Archivo exportado exitosamente a {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9802b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre del archivo: TransactionLookup (8).xls\n",
      "El archivo contiene TransactionLookup en el nombre.\n",
      "Lectura exitosa\n",
      "Archivo exportado exitosamente a C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado3.xlsx\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------Host Card Reports----------------------------------------------------------------------------------------------\n",
    "\n",
    "# Obtener una lista de todos los archivos Excel en la carpeta\n",
    "file_list = [os.path.join(host_folder_path, f) for f in os.listdir(host_folder_path) if f.endswith(('.xls', '.xlsx'))]\n",
    "\n",
    "HostDataframes = []\n",
    "for file in file_list:\n",
    "    file_name = os.path.basename(file)\n",
    " \n",
    "\n",
    "    if \"TransactionLookup\" in file_name:        \n",
    "        df_host = pd.read_excel(file, skiprows=4)\n",
    "        df_host  = df_host [3:]  # Eliminar las filas de encabezado original (0, 1 y 2)\n",
    "        df_host.reset_index(drop=True, inplace=True)\n",
    "        df_host['file_name'] = os.path.basename(file)# Agregar el nombre del archivo    \n",
    "        print(\"Nombre del archivo:\", file_name)\n",
    "        df_host['Seq'] = df_host['Seq'].astype(str)\n",
    "        df_host['PAN'] = df_host['PAN'].astype(str) \n",
    "        df_host['Amt. Req']  = df_host['Amt. Req'].str.replace(',', '', regex=False).astype(str) \n",
    "        df_host['Amt. Disp'] = df_host['Amt. Disp'].str.replace(',', '', regex=False).astype(str) \n",
    "        df_host['Amt. Req']  = pd.to_numeric(df_host['Amt. Req'].str.replace('$', '', regex=False), errors='coerce').astype(float)\n",
    "        df_host['Amt. Disp'] = pd.to_numeric(df_host['Amt. Disp'].str.replace('$', '', regex=False), errors='coerce').astype(float)\n",
    "        df_host = df_host.fillna(0)\n",
    "\n",
    "        print(\"El archivo contiene TransactionLookup en el nombre.\")\n",
    "\n",
    "    elif \"rpttransactiondetailbytid\" in file_name:\n",
    "        df_host = pd.read_excel(file, skiprows=5)\n",
    "        df_host  = df_host [4:]  # Eliminar las filas de encabezado original (0, 1 y 2)\n",
    "        df_host.reset_index(drop=True, inplace=True)\n",
    "        df_host['file_name'] = os.path.basename(file)# Agregar el nombre del archivo    \n",
    "        print(\"Nombre del archivo:\", file_name)\n",
    "        print (\"Transformacion Nulos\\n\")\n",
    "        df_host = df_host.dropna(axis=1, how='all')\n",
    "        print(\"El archivo contiene 'rpttransactiondetailbytid' en el nombre.\")  # Agregar el nombre del archivo  \n",
    "\n",
    "    else:\n",
    "        print(\"otra Opcion\") \n",
    "    #df_host = df_host.rename(columns={\"CS25DATE & TIME\": \"DATE & TIME\"})\n",
    "    dataframes.append(df_host)\n",
    "\n",
    "print(\"Lectura exitosa\")\n",
    "df_host.to_excel(output_path3, index=False, engine='openpyxl')  # Usa openpyxl como motor\n",
    "print(f\"Archivo exportado exitosamente a {output_path3}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf579abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+----------+--------------+---------------+--------------+-------------+-----------------+------+---------+--------------------+-----------+----+-------+--------------------+----------+-----+----+--------+--------+---------+---------+----------+---------+---------+-----------+---------+------+--------+------+----+--------------------+-------------------+\n",
      "|        DATE & TIME|  SEQUENCENUMBER|CARDNUMBER|hostseq_number|TRANSACTIONTYPE|TRANSAMOUNT($)|COINSTOTAL($)|DISPENSEDTOTAL($)|FEE($)|   STATUS|           file_name|Terminal ID| seq|TraceID|       Txn Date/Time|Sett  Date|  PAN|Type|FromAcct|Amt. Req|Amt. Disp|Amt. Schg|Amt. Total|Amt. Gtwy|Amt. Ichg|Switch Auth|Gat. Auth|Issuer|     ISO|Status| EMV|           file_name|found_in_datastream|\n",
      "+-------------------+----------------+----------+--------------+---------------+--------------+-------------+-----------------+------+---------+--------------------+-----------+----+-------+--------------------+----------+-----+----+--------+--------+---------+---------+----------+---------+---------+-----------+---------+------+--------+------+----+--------------------+-------------------+\n",
      "|08/23/2024 11:21:22|2024082311204808|      1205|          1470|     Withdrawal|         200.0|            0|            200.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1470|     -1|8/23/2024 11:28:3...|2024-08-23|X1205| WTH|     CHQ|   200.0|    200.0|    $4.95|   $204.95|  $204.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 08:13:19|2024082308124108|      7816|          1452|     Withdrawal|         100.0|            0|            100.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1452|     -1|8/23/2024 8:20:30 AM|2024-08-23|X7816| WTH|     CHQ|   100.0|    100.0|    $4.95|   $104.95|  $104.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 09:06:48|2024082309063308|      2610|             0|     Withdrawal|        1000.0|            0|              0.0|   0.0|   Denied|ATM_Transaction_S...|       NULL|NULL|   NULL|                NULL|      NULL| NULL|NULL|    NULL|    NULL|     NULL|     NULL|      NULL|     NULL|     NULL|       NULL|     NULL|  NULL|    NULL|  NULL|NULL|                NULL|              false|\n",
      "|08/23/2024 09:56:44|2024082309562708|      2056|             0|     Withdrawal|         400.0|            0|              0.0|   0.0|   Denied|ATM_Transaction_S...|       NULL|NULL|   NULL|                NULL|      NULL| NULL|NULL|    NULL|    NULL|     NULL|     NULL|      NULL|     NULL|     NULL|       NULL|     NULL|  NULL|    NULL|  NULL|NULL|                NULL|              false|\n",
      "|08/23/2024 10:03:23|2024082310031408|      1794|             0|     Withdrawal|         500.0|            0|              0.0|   0.0|   Denied|ATM_Transaction_S...|       NULL|NULL|   NULL|                NULL|      NULL| NULL|NULL|    NULL|    NULL|     NULL|     NULL|      NULL|     NULL|     NULL|       NULL|     NULL|  NULL|    NULL|  NULL|NULL|                NULL|              false|\n",
      "|08/23/2024 11:37:48|2024082311372608|      0154|             0|     Withdrawal|         200.0|            0|              0.0|   0.0|   Denied|ATM_Transaction_S...|       NULL|NULL|   NULL|                NULL|      NULL| NULL|NULL|    NULL|    NULL|     NULL|     NULL|      NULL|     NULL|     NULL|       NULL|     NULL|  NULL|    NULL|  NULL|NULL|                NULL|              false|\n",
      "|08/23/2024 11:39:33|2024082311390308|      6070|          1476|     Withdrawal|         140.0|            0|            140.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1476|     -1|8/23/2024 11:46:5...|2024-08-23|X6070| WTH|     CHQ|   140.0|    140.0|    $4.95|   $144.95|  $144.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 12:03:16|2024082312024208|      7912|          1488|     Withdrawal|         120.0|            0|            120.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1488|     -1|8/23/2024 12:10:3...|2024-08-24|X7912| WTH|     SAV|   120.0|    120.0|    $4.95|   $124.95|  $124.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 08:46:09|2024082308453408|      4299|          1454|     Withdrawal|         600.0|            0|            600.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1454|     -1|8/23/2024 8:53:25 AM|2024-08-23|X4299| WTH|     CHQ|   600.0|    600.0|    $4.95|   $604.95|  $604.95|    $0.23|   Approved|      0.0|730002|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 08:27:15|2024082308262908|      9584|          1453|     Withdrawal|          60.0|            0|             60.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1453|     -1|8/23/2024 8:34:26 AM|2024-08-23|X9584| WTH|     CHQ|    60.0|     60.0|    $4.95|    $64.95|   $64.95|    $0.47|   Approved|      0.0|702002|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 10:25:41|2024082310251008|      1804|          1464|     Withdrawal|         100.0|            0|            100.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1464|     -1|8/23/2024 10:33:0...|2024-08-23|X1804| WTH|     CHQ|   100.0|    100.0|    $4.95|   $104.95|  $104.95|    $0.23|   Approved|      0.0|730002|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 12:07:47|2024082312065408|      4153|          1490|     Withdrawal|         200.0|            0|            200.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1490|     -1|8/23/2024 12:14:4...|2024-08-24|X4153| WTH|     CHQ|   200.0|    200.0|    $4.95|   $204.95|  $204.95|    $0.38|   Approved|      0.0|773002|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 11:28:11|2024082311273708|      4467|          1472|     Withdrawal|         200.0|            0|            200.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1472|     -1|8/23/2024 11:35:2...|2024-08-23|X4467| WTH|     CHQ|   200.0|    200.0|    $4.95|   $204.95|  $204.95|    $0.16|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 12:05:12|2024082312043608|      4053|          1489|     Withdrawal|         400.0|            0|            400.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1489|     -1|8/23/2024 12:12:2...|2024-08-24|X4053| WTH|     CHQ|   400.0|    400.0|    $4.95|   $404.95|  $404.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 09:08:19|2024082309074608|      6718|          1456|     Withdrawal|        1000.0|            0|           1000.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1456|     -1|8/23/2024 9:15:35 AM|2024-08-23|X6718| WTH|     CHQ|  1000.0|   1000.0|    $4.95| $1,004.95|$1,004.95|    $0.38|   Approved|      0.0|773002|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 11:05:10|2024082311043708|      0608|          1468|     Withdrawal|          60.0|            0|             60.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1468|     -1|8/23/2024 11:12:2...|2024-08-23|X0608| WTH|     CHQ|    60.0|     60.0|    $4.95|    $64.95|   $64.95|    $0.16|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 11:46:52|2024082311461308|      9613|          1479|     Withdrawal|          60.0|            0|             60.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1479|     -1|8/23/2024 11:54:0...|2024-08-23|X9613| WTH|     CHQ|    60.0|     60.0|    $4.95|    $64.95|   $64.95|    $0.16|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 11:43:51|2024082311430608|      0154|          1478|     Withdrawal|         200.0|            0|            200.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1478|     -1|8/23/2024 11:50:5...|2024-08-23|X0154| WTH|     CHQ|   200.0|    200.0|    $4.95|   $204.95|  $204.95|    $0.16|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 10:51:02|2024082310502608|      7921|          1467|     Withdrawal|        1600.0|            0|           1600.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1467|     -1|8/23/2024 10:58:1...|2024-08-23|X7921| WTH|     CHQ|  1600.0|   1600.0|    $4.95| $1,604.95|$1,604.95|    $0.11|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "|08/23/2024 10:04:30|2024082310034208|      1794|          1463|     Withdrawal|         360.0|            0|            360.0|   0.0|Completed|ATM_Transaction_S...|   DMR00006|1463|     -1|8/23/2024 10:11:3...|2024-08-23|X1794| WTH|     CHQ|   360.0|    360.0|    $4.95|   $364.95|  $364.95|    $0.16|   Approved|      0.0|734004|Passport|    OK|    |TransactionLookup...|               true|\n",
      "+-------------------+----------------+----------+--------------+---------------+--------------+-------------+-----------------+------+---------+--------------------+-----------+----+-------+--------------------+----------+-----+----+--------+--------+---------+---------+----------+---------+---------+-----------+---------+------+--------+------+----+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Archivo exportado exitosamente a C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado3.xlsx\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------SPARK Consolidado\n",
    "\n",
    "#import os\n",
    "#os.environ[\"PYSPARK_PYTHON\"] = \"python3\"  # O \"python\" si ese es tu ejecutable\n",
    "spark = SparkSession.builder.appName(\"Host_LO Comparative\").getOrCreate()\n",
    "\n",
    "#Pandas a Spark\n",
    "\n",
    "dfLO = spark.createDataFrame(df_combined)\n",
    "dfHOST = spark.createDataFrame(df_host)\n",
    "\n",
    "\n",
    "#Renombre de columnas\n",
    "dfLO = dfLO.withColumnRenamed(\"HOSTSEQ NUMBER\", \"hostseq_number\")\n",
    "dfHOST = dfHOST.withColumnRenamed(\"Seq\", \"seq\")\n",
    "\n",
    "# Filtrar el DataFrame dfLO\n",
    "#dfLO = dfLO.filter(F.col(\"STATUS\") != \"Denied\")\n",
    "dfLO = dfLO.filter(F.col(\"TRANSACTIONTYPE\") != \"Balance inquiry\")\n",
    "\n",
    "\n",
    "#Verificación\n",
    "#print('Dataframe de LiveOffice')\n",
    "#dfLO.printSchema()\n",
    "#print('Dataframe de Host')\n",
    "#dfHOST.printSchema()\n",
    "\n",
    "joined_df = dfLO.join(\n",
    "    dfHOST,\n",
    "    dfLO[\"hostseq_number\"] == dfHOST[\"seq\"],\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "# Agregar columna de indicador\n",
    "result_df = joined_df.withColumn(\n",
    "    \"found_in_datastream\",\n",
    "    F.when(F.col(\"seq\").isNotNull(), True).otherwise(False)\n",
    ")\n",
    "\n",
    "result_df.show()\n",
    "\n",
    "#unmatched_df.show()\n",
    "# Convertir el DataFrame de Spark a Pandas\n",
    "pandas_df = result_df.toPandas()\n",
    "pandas_df.to_excel(output_path3, index=False, engine='openpyxl')  # Usa openpyxl como motor\n",
    "print(f\"Archivo exportado exitosamente a {output_path3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c7497f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['seqNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"seqNumber\":\"(\\d+)\"').astype(str)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['AuthNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"AuthNumber\":\"(\\d+)\"').astype(str)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['Amount'] = target_rows[\"FilteredData\"].str.extract(r'\"Amount\":([0-9]+(?:\\.[0-9]+)?)')\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['DispensedTotal'] = target_rows[\"FilteredData\"].str.extract(r'\"DispensedTotal\":([0-9]+(?:\\.[0-9]+)?)')\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['TransactionType'] = target_rows[\"FilteredData\"].str.extract(r'\"TransactionType\":\"([^\"]+)\"').astype(str)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['Status'] = target_rows[\"FilteredData\"].str.extract(r'\"Status\":\"([^\"]+)\"').astype(str)\n",
      "C:\\Users\\paula\\AppData\\Local\\Temp\\ipykernel_22252\\1389366263.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target_rows['JournalName'] = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             FilteredData         seqNumber  \\\n",
      "225     ___00:09:12 403002 ATM.     'Posting Transacti...  2024082300085508   \n",
      "452     ___00:18:28 403002 ATM.     'Posting Transacti...  2024082300181108   \n",
      "704     ___00:19:37 403002 ATM.     'Posting Transacti...  2024082300190208   \n",
      "958     ___00:20:40 403002 ATM.     'Posting Transacti...  2024082300201108   \n",
      "1212    ___00:32:37 403002 ATM.     'Posting Transacti...  2024082300320708   \n",
      "...                                                   ...               ...   \n",
      "331402  ___23:32:11 403002 ATM.     'Posting Transacti...  2024083123313808   \n",
      "331656  ___23:33:22 403002 ATM.     'Posting Transacti...  2024083123325408   \n",
      "331887  ___23:39:43 403002 ATM.     'Posting Transacti...  2024083123393208   \n",
      "332139  ___23:40:28 403002 ATM.     'Posting Transacti...  2024083123395108   \n",
      "332395  ___23:47:35 403002 ATM.     'Posting Transacti...  2024083123465708   \n",
      "\n",
      "       AuthNumber  Amount DispensedTotal TransactionType     Status  \\\n",
      "225           nan    60.0            0.0         WDRAWTX     DENIED   \n",
      "452           nan   200.0            0.0         WDRAWTX     DENIED   \n",
      "704          1431   100.0          100.0         WDRAWTX  COMPLETED   \n",
      "958          1432   200.0          200.0         WDRAWTX  COMPLETED   \n",
      "1212         1433   200.0          200.0         WDRAWTX  COMPLETED   \n",
      "...           ...     ...            ...             ...        ...   \n",
      "331402       3032   500.0          500.0         WDRAWTX  COMPLETED   \n",
      "331656       3033   100.0          100.0         WDRAWTX  COMPLETED   \n",
      "331887        nan  1300.0            0.0         WDRAWTX     DENIED   \n",
      "332139       3036  1000.0         1000.0         WDRAWTX  COMPLETED   \n",
      "332395       3037   400.0          400.0         WDRAWTX  COMPLETED   \n",
      "\n",
      "       JournalName  \n",
      "225            ATM  \n",
      "452            ATM  \n",
      "704            ATM  \n",
      "958            ATM  \n",
      "1212           ATM  \n",
      "...            ...  \n",
      "331402         ATM  \n",
      "331656         ATM  \n",
      "331887         ATM  \n",
      "332139         ATM  \n",
      "332395         ATM  \n",
      "\n",
      "[1354 rows x 8 columns]\n",
      "Archivo exportado exitosamente a C:\\Users\\paula\\UNIR\\MasterBigDatayVisualAnalytics\\cuatrimestre2\\TFM-TFE\\Entrega3\\TESIS_Maestria_ETL\\ETLProyect\\ArchivosSalida\\Concatenado2.xlsx\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------Logs Extraction-------------------------------------------------------------------------------\n",
    "# Crear una lista para almacenar los DataFrames\n",
    "logs_dataframes = []\n",
    "\n",
    "\n",
    "column_names = [\"FilteredData\"]\n",
    "\n",
    "# Iterar por los archivos en la carpeta\n",
    "for archivo in os.listdir(Logs_path):\n",
    "    if archivo.endswith('.jrn'):  # Filtrar solo archivos con extensión .jrn\n",
    "        ruta_completa = os.path.join(Logs_path, archivo)\n",
    "        logs_df = pd.read_csv(ruta_completa, sep=';', encoding='utf-8', names=column_names,header=None)  # Ajusta el separador si es necesario\n",
    "        logs_dataframes.append(logs_df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_completo = pd.concat(logs_dataframes, ignore_index=True)\n",
    "\n",
    "# Paso 1: Filtrar filas que contienen el texto \"ATM. 'Posting Transaction Result\"\n",
    "target_rows = df_completo[\n",
    "    df_completo.apply(lambda row: row.astype(str).str.contains(\"ATM.     'Posting Transaction Result \").any(), axis=1)\n",
    "]\n",
    "\n",
    "# Usar expresiones regulares para extraer los valores\n",
    "target_rows['seqNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"seqNumber\":\"(\\d+)\"').astype(str)\n",
    "target_rows['AuthNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"AuthNumber\":\"(\\d+)\"').astype(str)\n",
    "target_rows['Amount'] = target_rows[\"FilteredData\"].str.extract(r'\"Amount\":([0-9]+(?:\\.[0-9]+)?)')\n",
    "target_rows['DispensedTotal'] = target_rows[\"FilteredData\"].str.extract(r'\"DispensedTotal\":([0-9]+(?:\\.[0-9]+)?)')\n",
    "target_rows['TransactionType'] = target_rows[\"FilteredData\"].str.extract(r'\"TransactionType\":\"([^\"]+)\"').astype(str)\n",
    "target_rows['Status'] = target_rows[\"FilteredData\"].str.extract(r'\"Status\":\"([^\"]+)\"').astype(str)\n",
    "target_rows['JournalName'] = (\n",
    "    target_rows[\"FilteredData\"]\n",
    "    .str.extract(r'\\d+\\s+([^\\s]+)\\s+\\'Posting Transaction Result')  # Extraer el texto relevante\n",
    "    .squeeze()  # Convertir a una Serie si es un DataFrame con una sola columna\n",
    "    .str.replace(r'\\.', '', regex=True)  # Eliminar el punto\n",
    ")\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "#print(target_rows[['AuthNumber', 'seqNumber']])\n",
    "\n",
    "print(target_rows)\n",
    "\n",
    "target_rows.to_excel(output_path, index=False, engine='openpyxl')  # Usa openpyxl como motor\n",
    "print(f\"Archivo exportado exitosamente a {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_Logscompleto = pd.concat(logs_dataframes, ignore_index=True)\n",
    "\n",
    "# Paso 1: Filtrar filas que contienen el texto \"ATM. 'Posting Transaction Result\"\n",
    "target_rows = df_Logscompleto[\n",
    "    df_Logscompleto.apply(lambda row: row.astype(str).str.contains(\"ATM.     'Posting Transaction Result \").any(), axis=1)\n",
    "]\n",
    "\n",
    "# Usar expresiones regulares para extraer los valores\n",
    "target_rows['seqNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"seqNumber\":\"(\\d+)\"').astype(str)\n",
    "target_rows['AuthNumber'] = target_rows[\"FilteredData\"].str.extract(r'\"AuthNumber\":\"(\\d+)\"').astype(str)\n",
    "target_rows['Amount'] = target_rows[\"FilteredData\"].str.extract(r'\"Amount\":([0-9]+(?:\\.[0-9]+)?)')\n",
    "target_rows['DispensedTotal'] = target_rows[\"FilteredData\"].str.extract(r'\"DispensedTotal\":([0-9]+(?:\\.[0-9]+)?)')\n",
    "target_rows['TransactionType'] = target_rows[\"FilteredData\"].str.extract(r'\"TransactionType\":\"([^\"]+)\"').astype(str)\n",
    "target_rows['Status'] = target_rows[\"FilteredData\"].str.extract(r'\"Status\":\"([^\"]+)\"').astype(str)\n",
    "target_rows['JournalName'] = (\n",
    "    target_rows[\"FilteredData\"]\n",
    "    .str.extract(r'\\d+\\s+([^\\s]+)\\s+\\'Posting Transaction Result')  # Extraer el texto relevante\n",
    "    .squeeze()  # Convertir a una Serie si es un DataFrame con una sola columna\n",
    "    .str.replace(r'\\.', '', regex=True)  # Eliminar el punto\n",
    ").astype(str)\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "#print(target_rows[['AuthNumber', 'seqNumber']])\n",
    "\n",
    "print(target_rows)\n",
    "\n",
    "target_rows.to_excel(output_path, index=False, engine='openpyxl')  # Usa openpyxl como motor\n",
    "print(f\"Archivo exportado exitosamente a {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbf0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
